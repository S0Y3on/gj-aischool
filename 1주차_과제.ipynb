{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsNOXZNe6QPJ++0h2JFunL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S0Y3on/gj-aischool/blob/master/1%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omLYIJhQdrUo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUMG09DAl0eP",
        "colab_type": "text"
      },
      "source": [
        "#1주차 과제\n",
        "\n",
        "**1. 언어**\n",
        "\n",
        " \n",
        "\n",
        "\n",
        ">   파파고는 지난 2017년 네이버에서 정식 출시되어 서비스 한지 1년 10개월 만에 월간 활성 이용자 수(MAU)가 1000만명을 넘겼다고 밝혀졌다. 파파고는 인공지능 통/번역 서비스와 한국어, 영어, 중국어는 이미지 번역 기능도 사용할 수 있다. \n",
        "\n",
        "  파파고는 Neural Machine Translation (인공신경망 기반 기계번역) 기술을 사용하는데 이 기술은 입력 문장을 문장 벡터로 변환하는 신경망(encoder)과 문장 벡터에서 번역하는 언어의 문장을 생성하는 신경망(decoder)을 대규모 병렬 코퍼스(말뭉치)부터 자동으로 학습한다. 입력 문장의 일부가 아닌 문장 전체 정보를 바탕으로 번역을 수행하여 기존 SMT(Statistical Machine Translation - 통신 기계 번역)방식의 번역보다 정확하고 문장 맥락에 맞는 번역을 제공한다. 또한 입력된 문장 중 유사한 뜻을 가진 문장은 서로 가깝게 모여 있게 되는데, NMT는 입력된 문장 주변에 있는 정보들을 참고하여 문장의 맥락을 이해하고, 보다 자연스러운 번역 결과를 만든다 .그리고 네이버 서비스를 통해 축적해온 번역 품질에 대한 피드백들을 적극적으로 활용하여 단순 통계에만 의존하지 않고 문제점을 보완 해나갈 수 있었다.\n",
        "\n",
        "  기존에 언어의 문법을 규칙화 하여 번역하는 규칙기반 기계번역(RBMT – Rule-Based Machine Translation)과 빅 데이터를 이용해 통계적으로 규칙을 생성해 번역하는 통계방식 번역(SMT – Statistical Machine Translation) 과 같은 기술을 이용했을 때, 문맥이 어색한 번역에 벗어나지 못했다. 최근 인공지능과 신경 네트워크를 기반으로 하는 기계 번역이 발전하고 있다. 신경형 기계 번역(NMT – Neural Machine Translation)은 단어나 구문이 가진 여러가지 의미를 저장해 놓는 시스템 이다. \n",
        " 그리고 어텐션 메커니즘(attention mechanism)을 사용하는데, 이 기술은 특정 벡터(자료조직)에 집중해 성능을 최대한 높이는 방법이다. 하지만 하나의 고정된 크기의 벡터에 모든 정보를 압축하려하다 보니 번역시 필요한 정보가 손실된다는 단점이 있다.\n",
        "\n",
        "\n",
        "\n",
        "**2. 음성**\n",
        "\n",
        ">  소리자바라는 회사는 다양한 인공지능 서비스를 제공한다. 그 중 AI 속기사라는 제품을 판매하는데, 기존 속기 방식은 대화자의 발언이 겹칠 경우 청취 및 속기가 불가능 하고, 속기사의 타자 능력에만 의존한다. \n",
        "\n",
        "  인공지능 속기 방식은 소프트파워를 통한 속기의 지능화, 끊임없는 학습으로 스스로 진화, 빠른 속도의 무제한 자동 입력, 인간이 구분할 수 없던 영역의 중복발언까지 인식할 수 있다. 그리고 반복되는 작업은 자동처리할 수 있다. \n",
        " 이 서비스를 위한 기술 중 음성인식이 있다. 음성인식(Speech Recognition)이란 사람이 말하는 음성 언어를 컴퓨터가 해석해 그 내용을 문자데이터로 전환하는 처리를 말하며 STT(Speech-to-Text)라고도 한다. \n",
        "\n",
        " 주로 사용하는 알고리즘은 HMM(Hidden Markov Model)으로서, 다양한 화자들이 발성한 음성들을 통계적으로 모델링하여 음향모델을 구성하며 말뭉치 수집을 통하여 언어모델을 구성한다. 미리 기록해 둔 음성 패턴과 비교해 개인 인증 등의 용도로 사용하기도 하는데 이를 화자 인식이라고 한다.\n",
        "\n",
        "\n",
        "\n",
        "**3. 이미지**\n",
        "\n",
        "> 지난 3월 알리바바의 인공지능을 연구 개발하는 알리바바 달마 연구소(Alibaba Dharma Institute)와 알리바바 클라우드(Alibaba Cloud)는 폐렴의 임상 진단을 위한 컴퓨터 단층 촬영(CT) 이미지에서 인공지능(AI) 진단 세트(Dharma Hospital Medical AI)를 개발했으며, 의료진의 임상 진단 효율성을 향상시켜 96 %에 도달했으며, 일주일 만에 30,000 여회 의심되는 폐렴 사례를 식별했다고 밝혔었다.\n",
        "\n",
        "  인공지능(AI) 기반 화상 진단 분야에서는 데이터가 곧 AI의 성능을 좌우한다. 이런 풍부한 코로나19 데이터를 기반으로 공산주의인 중국이 가장 빠른 발전을 보이고 있다. \n",
        " 중국 전역의 코로나 확진자 5천 명 가량의 이미지와 데이터를 활용해 자연 언어 처리(NLP)와 컨볼루션 신경망(CNN, Convolutional Neural Network)을 사용하여 CT 이미지의 인식 네트워크를 훈련시켜 새로운 관상 폐렴 이미지와 일반 폐렴 이미지의 차이를 신속하게 식별할 수 있었으며, 또 AI는 병변 부위의 비율을 직접 계산하여 질병의 중증도를 정량화할 수 있다.\n",
        "\n",
        "자연 언어 처리(Natural Language Processing, 이하 NLP)는 컴퓨터와 인간 언어 사이의 상호 작용하는 기술이고,\n",
        "컨벌루션 뉴럴 네트워크(CNN 또는 ConvNet)는 모델이 직접 이미지, 비디오, 텍스트 또는 사운드를 분류하는 머신 러닝의 한 유형인 딥러닝에 가장 많이 사용되는 알고리즘이다. CNN은 이미지에서 객체, 얼굴, 장면을 인식하기 위해 패턴을 찾는데 특히 유용하다. 또한 CNN은 데이터에서 직접 학습하며, 패턴을 사용하여 이미지를 분류하고 특징을 수동으로 추출할 필요가 없다.\n",
        "\n",
        "그리고 CNN은 합성곱(Convolution) 연산을 사용하는 인공신경망의 한 종류이다. \n",
        "Convolution을 사용하면 3차원 데이터의 공간적 정보를 유지한 채 다음 레이어로 보낼 수 있다.\n",
        "대표적인 CNN으로 LeNet(1998)과 AlexNet(2012)가 있고, VGG, GoogLeNet, ResNet 등은 층을 더 깊게 쌓은 CNN기반의 심층 신경망(DNN)이다. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**4. 자율주행**\n",
        "\n",
        "\n",
        ">테슬라 오토파일럿은 테스라모터스가 전기 자동차 모델S에 자동 운전 모드 소프트웨어를 추가하여 만든 자동주행시스템을 말한다.\n",
        "자동 운전 차량으로 사람이 운전하지 않고 차량이 자동 운전하는 것이며, 미래에는 자동운전 차량이 일반화되어 핸들을 잡는 것이 허용되지 않을 것으로 예측된다.\n",
        "\n",
        " 사용되는 기술로는 Semantic Segmentation, HydraNet, 깊이 예측 & 멀티플 HydraNet, FSD (Full-Self Driving) 등이 있다. \n",
        "Semantic Segmentation은 단순히 사진을 분류하는 것이 아니라 그 장면을 완벽하게 이해하는 높은 수준의 문제이다. 주로 다뤄지는 문제는 분류, 발견, 분할 등이 있다.  \n",
        "\n",
        "*분류 (Classification)*: 인풋(Input)에 대한 레이블(Label)을 예측하는 작업이다. 대표적인 모델로 AlexNet, ResNet, Xception, \n",
        "\n",
        "*발견 (Localization / Detection)*: 레이블을 예측하면서 그 대상이 어디에 있는지 라벨링(Labeling) 등을 하며 정보를 제공한다. 대표 모델로 YOLO, R-CNN, \n",
        "\n",
        "*분할 (Segmentation)*: 모든 픽셀에 대해서 레이블을 예측한다.  대표 모델로 FCN, SegNet, DeepLab\n",
        "\n",
        "\n",
        "  HydraNet은 핵심이 되는 백본(Backbone)위에 여러 작은 신경망이 올라가는 형태이다. \n",
        " 자율주행을 위해 도로, 사람, 차량, 신호, 표지판 등 분석해야 할 대상(태스크, Task)들이 거의 100개에 달하는데, 태스크마다 일일이 온전한 신경망을 만들기에는 여유가 없기 때문에 따라서 각 신경망들이 백본을 공유하는 형태를 가진다. \n",
        "\n",
        "깊이 예측 & 멀티플 HydraNet은 인간의 경우 양쪽 눈으로 대상을 보는데 왼쪽 눈과 오른쪽 눈, 해당 사물 이렇게 세 개가 삼각형 구조를 이룬다. 뇌는 이렇게 각 눈에서 오는 정보를 통합하여 대상의 멀고 가까움을 인지한다. 이를 모방하여 도로의 윤곽을 파악하기 위해 테슬라는 차량에 달린 8대의 카메라, 즉 8개의 HydraNet으로부터 사람처럼 삼각 측량을 통해 멀고 가까움을 인지한다. 한쪽 눈 보다는 양쪽 눈으로 볼 때 깊이를 더 잘 파악할 수 있는 것처럼, 한 HydraNet이 다른 HydraNet들로부터 이미지의 특징값들을 받아 원근을 측정한다. \n",
        "\n",
        "  FSD (Full-Self Driving) 칩은 테슬라가 자체 개발한 맞춤형 자율주행 칩으로, 높은 수준으로 표준 운영 체제를 부팅할 수 있는 시스템 온 칩(SoC)인다. 자율주행 인공지능 추론(Inference) 능력을 위해 차량 내부에 자체 개발한 FSD 칩을 탑재한다. "
      ]
    }
  ]
}